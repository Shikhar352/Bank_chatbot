{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ln6EsTkh29ga"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBPKY0TZ6AEJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5Hbi5jT7R17"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDEggce16ErN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqCGynB73BS0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tMtwMsD44FH5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AvkpU5q73aKb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8hPeFhCp3pPo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5M9LZt5RAM7K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iz4BMmjz30kH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OQBn909BHr3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zin4uA0W4Rbp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D-6uMjVHA-Sf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JDsRvlL4WLP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMgzwwH94ZGY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXaCzMDa4dBs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7hKiaVyBTXb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iS1DbDeG6cuc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import warnings\n",
        "import gradio as gr\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Load stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Load data (replace with your actual file path)\n",
        "try:\n",
        "    data = pd.read_csv(\"/content/BankFAQs.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'BankFAQs.csv' not found. Please upload the file to the Colab environment.\")\n",
        "    # You might want to exit or handle the error differently\n",
        "    exit()\n",
        "\n",
        "\n",
        "data[\"Cleaned_Question\"] = data[\"Question\"].apply(clean_text)\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"Class_Label\"] = label_encoder.fit_transform(data[\"Class\"])\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(data[\"Cleaned_Question\"])\n",
        "y = data[\"Class_Label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "classifier = SVC(kernel=\"linear\", probability=True)\n",
        "classifier.fit(X_train, y_train) # Fit the classifier\n",
        "\n",
        "\n",
        "def get_response(user_input):\n",
        "    try:\n",
        "        cleaned_input = clean_text(user_input)\n",
        "        input_vector = vectorizer.transform([cleaned_input])\n",
        "        predicted_class = classifier.predict(input_vector)[0]\n",
        "        class_questions = data[data[\"Class_Label\"] == predicted_class]\n",
        "        similarities = cosine_similarity(input_vector, vectorizer.transform(class_questions[\"Cleaned_Question\"]))\n",
        "        max_sim_index = similarities.argmax()\n",
        "        response = class_questions.iloc[max_sim_index][\"Answer\"]\n",
        "        return response\n",
        "    except (ValueError, IndexError) as e:\n",
        "        return f\"An error occurred: {e}. Please try a different query.\"\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your query here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Bank FAQ Chatbot\",\n",
        "    description=\"Ask me anything about accounts, investments, or funds.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "SKTpGNG_BtJH",
        "outputId": "081dfd32-b9e9-475b-e13c-ce3a234cfe29"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://80b12631e6e4541ff4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://80b12631e6e4541ff4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "py9DKPqZ__15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_g31NPn94kel"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkcwojiS4nd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OgK68QbS6vJw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIK1pWh37q-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}